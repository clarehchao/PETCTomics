{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numbers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import re\n",
    "from sklearn.metrics import roc_auc_score, auc, roc_curve\n",
    "from scipy.stats import zscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ID_var_name = 'pet_mr_radiomics'\n",
    "\n",
    "df_yr = range(1,6,1)\n",
    "outcome_names = ['DF_{}yr'.format(yy) for yy in df_yr]\n",
    "\n",
    "n_trial = 10\n",
    "k_fold = 3\n",
    "\n",
    "rootdir = '/Users/shuang/Documents/Proj_Radiomics/Data/her2'\n",
    "the_mri_tp = 2\n",
    "the_mri_bin_width = 5\n",
    "the_pet_bin_width = 0.1\n",
    "im_dir = '{}/her2_Analysis/PETMRI/PETbinwidth{:.1f}_MRItp{}_binwidth{}'.format(rootdir,the_pet_bin_width, the_mri_tp, the_mri_bin_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shuang/Packages/anaconda2/envs/tensorflow_py35/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:84: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# read the learning output data and more\n",
    "fname = '{}/Learner/CLF_output_all.csv'.format(im_dir)\n",
    "df_clf_all = pd.read_csv(fname)\n",
    "\n",
    "# simplify clf name\n",
    "def simplify_clf_name_func(x):\n",
    "    if re.search('(.+)LogReg',x):\n",
    "        return 'LogReg'\n",
    "    else:\n",
    "        return x\n",
    "df_clf_all['clf_name_simplify'] = df_clf_all['clf_name'].map(simplify_clf_name_func)\n",
    "# print(df_clf_all.ix[:,['clf_name_simplify', 'clf_name']])\n",
    "\n",
    "# # drop the one with Random Forest since we would like to use logistic regression only\n",
    "# df_clf_all.drop(df_clf_all[(df_clf_all.Dep_var == 'DF_1yr') & (df_clf_all.clf_name == 'RandomForest')].index, inplace=True)\n",
    "# idx = df_clf_all.groupby('Dep_var').apply(lambda df: df.AUC_mean.argmax())  \n",
    "\n",
    "dct_clf = {'ElasticNet': SGDClassifier(), 'LogReg': LogisticRegression(), 'RandomForest': RandomForestClassifier(),\n",
    "          'SVM': SVC()}\n",
    "\n",
    "# the selected model to use for all DF outcome\n",
    "the_clf_name = 'ElasticNet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/shuang/Documents/Proj_Radiomics/Data/her2/her2_Analysis/PETMRI/PETbinwidth0.1_MRItp2_binwidth5/Learner/ElasticNet_IDVpet_mr_radiomics_DVDF_1yr_Trial10_3folds.json\n",
      "/Users/shuang/Documents/Proj_Radiomics/Data/her2/her2_Analysis/PETMRI/PETbinwidth0.1_MRItp2_binwidth5/Learner/ElasticNet_IDV['FOstats_energy_mri' 'FOstats_entropy_mri' 'FOstats_kurtosis_mri'\n",
      " 'FOstats_mean_mri' 'FOstats_skewness_mri' 'FOstats_uniformity_mri'\n",
      " 'FOstats_variance_mri' 'ShapeSize_compactness1_mri'\n",
      " 'ShapeSize_compactness2_mri' 'ShapeSize_max_euc_dis_mri'\n",
      " 'ShapeSize_spherical_disproportion_mri' 'ShapeSize_sphericity_mri'\n",
      " 'ShapeSize_surf_area_cm2_mri' 'ShapeSize_surface2volratio_mri'\n",
      " 'ShapeSize_vol_cm3_mri' 'texture_autocorrelation_avg_mri'\n",
      " 'texture_cluster_prominence_avg_mri' 'texture_cluster_shade_avg_mri'\n",
      " 'texture_cluster_tendency_avg_mri' 'texture_contrast_avg_mri'\n",
      " 'texture_correlation_avg_mri' 'texture_diff_entropy_avg_mri'\n",
      " 'texture_dissimilarity_avg_mri' 'texture_energy_avg_mri'\n",
      " 'texture_entropy_avg_mri' 'texture_homogeneity1_avg_mri'\n",
      " 'texture_homogeneity2_avg_mri' 'texture_idmn_avg_mri'\n",
      " 'texture_idn_avg_mri' 'texture_inv_var_avg_mri' 'texture_maxprob_avg_mri'\n",
      " 'texture_sum_avg_avg_mri' 'texture_sum_entropy_avg_mri'\n",
      " 'texture_sum_var_avg_mri' 'texture_imc1_avg_mri' 'texture_imc2_avg_mri'\n",
      " 'texture_diff_avg_avg_mri' 'texture_diff_var_avg_mri'\n",
      " 'texture_avg_intensity_avg_mri' 'texture_sum_squares_avg_mri'\n",
      " 'FOstats_min_mri' 'FOstats_max_mri' 'FOstats_energy_pet'\n",
      " 'FOstats_entropy_pet' 'FOstats_kurtosis_pet' 'FOstats_mean_pet'\n",
      " 'FOstats_min_pet' 'FOstats_max_pet' 'FOstats_skewness_pet'\n",
      " 'FOstats_uniformity_pet' 'FOstats_variance_pet'\n",
      " 'ShapeSize_compactness1_pet' 'ShapeSize_compactness2_pet'\n",
      " 'ShapeSize_max_euc_dis_pet' 'ShapeSize_spherical_disproportion_pet'\n",
      " 'ShapeSize_sphericity_pet' 'ShapeSize_surf_area_cm2_pet'\n",
      " 'ShapeSize_surface2volratio_pet' 'ShapeSize_vol_cm3_pet'\n",
      " 'texture_autocorrelation_avg_pet' 'texture_cluster_prominence_avg_pet'\n",
      " 'texture_cluster_shade_avg_pet' 'texture_cluster_tendency_avg_pet'\n",
      " 'texture_contrast_avg_pet' 'texture_correlation_avg_pet'\n",
      " 'texture_diff_entropy_avg_pet' 'texture_dissimilarity_avg_pet'\n",
      " 'texture_energy_avg_pet' 'texture_entropy_avg_pet'\n",
      " 'texture_homogeneity1_avg_pet' 'texture_homogeneity2_avg_pet'\n",
      " 'texture_idmn_avg_pet' 'texture_idn_avg_pet' 'texture_inv_var_avg_pet'\n",
      " 'texture_maxprob_avg_pet' 'texture_sum_avg_avg_pet'\n",
      " 'texture_sum_entropy_avg_pet' 'texture_sum_var_avg_pet'\n",
      " 'texture_imc1_avg_pet' 'texture_imc2_avg_pet' 'texture_diff_avg_avg_pet'\n",
      " 'texture_diff_var_avg_pet' 'texture_avg_intensity_avg_pet'\n",
      " 'texture_sum_squares_avg_pet']_DVDF_2yr_Trial10_3folds.json\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected object or value",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-f219c989aa29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mjson_fname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'{}/Learner/{}_IDV{}_DV{}_Trial{}_{}folds.json'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthe_clf_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeat_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_fold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_fname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mdf_learning_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_fname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mii\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf_learning_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mfeat_imp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_learning_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'feat_importance'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/shuang/Packages/anaconda2/envs/tensorflow_py35/lib/python3.5/site-packages/pandas/io/json.py\u001b[0m in \u001b[0;36mread_json\u001b[0;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit, encoding, lines)\u001b[0m\n\u001b[1;32m    279\u001b[0m         obj = FrameParser(json, orient, dtype, convert_axes, convert_dates,\n\u001b[1;32m    280\u001b[0m                           \u001b[0mkeep_default_dates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecise_float\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m                           date_unit).parse()\n\u001b[0m\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'series'\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/shuang/Packages/anaconda2/envs/tensorflow_py35/lib/python3.5/site-packages/pandas/io/json.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_no_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/shuang/Packages/anaconda2/envs/tensorflow_py35/lib/python3.5/site-packages/pandas/io/json.py\u001b[0m in \u001b[0;36m_parse_no_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0morient\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m             self.obj = DataFrame(\n\u001b[0;32m--> 566\u001b[0;31m                 loads(json, precise_float=self.precise_float), dtype=None)\n\u001b[0m\u001b[1;32m    567\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0morient\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"split\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m             decoded = dict((str(k), v)\n",
      "\u001b[0;31mValueError\u001b[0m: Expected object or value"
     ]
    }
   ],
   "source": [
    "# find 'important' features\n",
    "for oc in outcome_names:\n",
    "    json_fname = '{}/Learner/{}_IDV{}_DV{}_Trial{}_{}folds.json'.format(im_dir, the_clf_name, ID_var_name, oc, n_trial, k_fold)\n",
    "    print(json_fname)\n",
    "    df_learning_output = pd.read_json(json_fname)\n",
    "    for ii in df_learning_output.index:\n",
    "        feat_imp = np.array(df_learning_output['feat_importance'][ii])\n",
    "        feat_names = np.array(df_learning_output['feat_name'][ii])\n",
    "        \n",
    "        # find a list of features that are not dropped by ElasticNet\n",
    "        lst_tmp = feat_name[feat_imp != 0.0]\n",
    "        if ii == 0:\n",
    "            #initialize the dictionary\n",
    "            dct_feat_tally = {}\n",
    "            for ss in lst_tmp:\n",
    "                dct_feat_tally[ss] = 1\n",
    "        else:\n",
    "            for ss in lst_tmp:\n",
    "                if ss in dct_feat_tally.keys():\n",
    "                    dct_feat_tally[ss] += 1\n",
    "                else:\n",
    "                    dct_feat_tally[ss] = 1\n",
    "print(dct_feat_tally)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read in all radiomic data\n",
    "fname = '{}/data_all.csv'.format(im_dir)\n",
    "df_data = pd.read_csv(fname)\n",
    "pat = re.compile('texture_|FOstats_|ShapeSize_')\n",
    "feat_names = [ss for ss in df_data.columns.tolist() if pat.match(ss)]\n",
    "feat_tag = 'pet_mr_radiomics'\n",
    "\n",
    "# scale the features to z-score\n",
    "df_data[feat_names] = df_data[feat_names].apply(zscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31]\n",
      "/Users/shuang/Documents/Proj_Radiomics/Data/her2/her2_Analysis/PETMRI/PETbinwidth0.1_MRItp2_binwidth5/Learner/ElasticNet_IDVpet_mr_radiomics_DVDF_3yr_Trial10_3folds.json\n",
      "{'alpha': 0.68797000000000097, 'l1_ratio': 0.48666666666666664, 'max_iter': 49933.333333333336, 'loss': 'log', 'penalty': 'elasticnet'}\n",
      "SGDClassifier(alpha=0.68797000000000097, average=False, class_weight=None,\n",
      "       epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.48666666666666664, learning_rate='optimal', loss='log',\n",
      "       max_iter=49933.333333333336, n_iter=None, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       tol=None, verbose=0, warm_start=False)\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "test = [idx[3]]\n",
    "print(test)\n",
    "for ii in test:\n",
    "#     clf_name, clf_name_simple, oc, n_trial, k_fold = df_clf_all.ix[ii, ['clf_name', 'clf_name_simplify', 'Dep_var', 'n_trial', 'k_fold']].tolist()\n",
    "    json_fname = '{}/Learner/{}_IDV{}_DV{}_Trial{}_{}folds.json'.format(im_dir, the_clf_name, feat_name, oc, n_trial, k_fold)\n",
    "    df_learning_output = pd.read_json(json_fname)\n",
    "    lst_data_all = []\n",
    "    for iid in df_learning_output.index:\n",
    "        dct_param = df_learning_output['best_params'][iid]\n",
    "        if iid == 0: # determine what to average on the first round\n",
    "            lst_num_var = []\n",
    "            for k, val in dct_param.items():\n",
    "               if isinstance(val, numbers.Number):\n",
    "                lst_num_var.append(k)\n",
    "            lst_str_var = set(lst_num_var).symmetric_difference(dct_param.keys())\n",
    "        lst_tmp = [dct_param[s] for s in lst_num_var]\n",
    "        tmp = dict(zip(lst_num_var, lst_tmp))\n",
    "        lst_data_all.append(tmp)\n",
    "        \n",
    "    df_data_all = pd.DataFrame(lst_data_all)\n",
    "    df_data_all = df_data_all.ix[:, lst_num_var]\n",
    "    \n",
    "    # create the final parameter with the average over all numerical variables\n",
    "    final_param = dict(df_data_all.mean())\n",
    "    \n",
    "    # add the string parameter variabls\n",
    "    for ss in lst_str_var:\n",
    "        final_param[ss] = dct_param[ss]\n",
    "    print(final_param)\n",
    "        \n",
    "    # get all the needed radiomic data\n",
    "    df_tmp = df_data.ix[:,feat_names + [oc]]\n",
    "    df_tmp = df_tmp.dropna()\n",
    "    X, y = df_tmp.ix[:,feat_names].as_matrix(), df_tmp.ix[:,oc].astype('int').as_matrix()\n",
    "    clf = dct_clf[the_clf_name]\n",
    "    print(clf)\n",
    "    clf.set_params(**final_param)\n",
    "    clf.fit(X, y)\n",
    "    feat_importance = getattr(clf, 'feature_importances_', None)\n",
    "    if feat_importance is None and hasattr(clf, 'coef_'):\n",
    "        feat_importance = clf.coef_\n",
    "    print(feat_importance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['texture_idn_avg_mri' 'texture_cluster_shade_avg_pet']\n",
      "[ 0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.26841557  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.18527969\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.        ]\n"
     ]
    }
   ],
   "source": [
    "feat_imp = np.array(df_learning_output['feat_importance'][4])\n",
    "feat_name = np.array(df_learning_output['feat_name'][4])\n",
    "print(feat_name[feat_imp != 0.0])\n",
    "print(feat_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for easier interpretbaility of output, we will use elasticNet for reporting feature importance for all outcome!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_py35]",
   "language": "python",
   "name": "conda-env-tensorflow_py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
