{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numbers\n",
    "import operator\n",
    "import re\n",
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_var_name = 'pet_mr_radiomics'\n",
    "n_trial = 1000\n",
    "k_fold = 3\n",
    "\n",
    "rootdir = '/Users/shuang/Documents/Proj_Radiomics/Data/her2'\n",
    "the_mri_tp = 2\n",
    "the_mri_bin_width = 5\n",
    "the_pet_bin_width = 0.1\n",
    "im_dir = '{}/her2_Analysis/PETMRI/PETbinwidth{:.1f}_MRItp{}_binwidth{}'.format(rootdir,the_pet_bin_width, the_mri_tp, the_mri_bin_width)\n",
    "\n",
    "# the selected model to use for all DF outcome\n",
    "# the_clf_name = 'ElasticNet'\n",
    "# df_yr = range(1,6,1)\n",
    "# outcome_names = ['DF_{}yr'.format(yy) for yy in df_yr]\n",
    "\n",
    "the_clf_name = 'L2lbfgsLogReg'\n",
    "outcome_names = ['Tumor_Grade_Binary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find 'important' features for ElasticNet algorithm\n",
    "for oc in outcome_names:\n",
    "    json_fname = '{}/Learner/{}_IDV{}_DV{}_Trial{}_{}folds.json'.format(im_dir, the_clf_name, ID_var_name, oc, n_trial, k_fold)\n",
    "    df_learning_output = pd.read_json(json_fname)\n",
    "    for ii in df_learning_output.index:\n",
    "        feat_imp = np.array(df_learning_output['feat_importance'][ii])\n",
    "        feat_names = np.array(df_learning_output['feat_name'][ii])\n",
    "        \n",
    "        # find a list of features that are not dropped by ElasticNet\n",
    "        lst_tmp = feat_names[feat_imp != 0.0]\n",
    "        if ii == 0:\n",
    "            #initialize the dictionary\n",
    "            dct_feat_tally = {}\n",
    "            for ss in lst_tmp:\n",
    "                dct_feat_tally[ss] = 1\n",
    "        else:\n",
    "            for ss in lst_tmp:\n",
    "                if ss in dct_feat_tally.keys():\n",
    "                    dct_feat_tally[ss] += 1\n",
    "                else:\n",
    "                    dct_feat_tally[ss] = 1\n",
    "    \n",
    "    # sort the feat tally dictionary\n",
    "    sorted_dct_feat_tally = sorted(dct_feat_tally.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    top10_feat = sorted_dct_feat_tally[0:10]\n",
    "    \n",
    "    max_count = len(df_learning_output)\n",
    "    print('outcome: {}\\n'.format(oc))\n",
    "    for (feat, count) in top10_feat:\n",
    "        print('{} ({})'.format(feat, float(count/max_count)))\n",
    "    print('\\n')\n",
    "#     print(sorted_dct_feat_tally)\n",
    "#     for k, value in sorted_dct_feat_tally.items():\n",
    "#         print('feat name: {}, count: {}'.format(k, value))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([-0.0258225 , -0.01518348,  0.03563678, -0.02458551,  0.00206473,\n",
      "        0.00687059, -0.02282641, -0.00646505, -0.00464322, -0.03342172,\n",
      "       -0.02866758,  0.01878352, -0.03250961, -0.0172686 , -0.02874081,\n",
      "       -0.02373984, -0.02907081, -0.02892077, -0.02306865, -0.0231096 ,\n",
      "        0.00289675, -0.0156292 , -0.02249804,  0.01713002, -0.01112963,\n",
      "        0.01413147,  0.012689  ,  0.00532462,  0.01590337,  0.00794244,\n",
      "        0.0187878 , -0.02525588, -0.01503631, -0.02371352,  0.00782661,\n",
      "       -0.01133406, -0.02249804, -0.02332878, -0.02525588, -0.02317415,\n",
      "       -0.02199317, -0.02675036,  0.01043398,  0.03996115, -0.0144827 ,\n",
      "        0.03047159, -0.01886497,  0.02423152, -0.00213131, -0.03293564,\n",
      "        0.03032448,  0.01326739,  0.04698611, -0.0130042 , -0.0317089 ,\n",
      "        0.04123355,  0.00414635, -0.01809286,  0.01427789,  0.02982991,\n",
      "        0.02278305,  0.01158311,  0.03025274,  0.02784131,  0.0127952 ,\n",
      "        0.03930428,  0.03829733, -0.02842949,  0.03978501, -0.04513085,\n",
      "       -0.04525197, -0.03587959, -0.03081116, -0.04772073, -0.02944009,\n",
      "        0.03151904,  0.03897822,  0.02939359, -0.02546719,  0.040555  ,\n",
      "        0.03829733,  0.02536275,  0.03151904,  0.03021399]), array([ 0.0258225 ,  0.01518348,  0.03563678,  0.02458551,  0.00206473,\n",
      "        0.00687059,  0.02282641,  0.00646505,  0.00464322,  0.03342172,\n",
      "        0.02866758,  0.01878352,  0.03250961,  0.0172686 ,  0.02874081,\n",
      "        0.02373984,  0.02907081,  0.02892077,  0.02306865,  0.0231096 ,\n",
      "        0.00289675,  0.0156292 ,  0.02249804,  0.01713002,  0.01112963,\n",
      "        0.01413147,  0.012689  ,  0.00532462,  0.01590337,  0.00794244,\n",
      "        0.0187878 ,  0.02525588,  0.01503631,  0.02371352,  0.00782661,\n",
      "        0.01133406,  0.02249804,  0.02332878,  0.02525588,  0.02317415,\n",
      "        0.02199317,  0.02675036,  0.01043398,  0.03996115,  0.0144827 ,\n",
      "        0.03047159,  0.01886497,  0.02423152,  0.00213131,  0.03293564,\n",
      "        0.03032448,  0.01326739,  0.04698611,  0.0130042 ,  0.0317089 ,\n",
      "        0.04123355,  0.00414635,  0.01809286,  0.01427789,  0.02982991,\n",
      "        0.02278305,  0.01158311,  0.03025274,  0.02784131,  0.0127952 ,\n",
      "        0.03930428,  0.03829733,  0.02842949,  0.03978501,  0.04513085,\n",
      "        0.04525197,  0.03587959,  0.03081116,  0.04772073,  0.02944009,\n",
      "        0.03151904,  0.03897822,  0.02939359,  0.02546719,  0.040555  ,\n",
      "        0.03829733,  0.02536275,  0.03151904,  0.03021399]))\n",
      "[u'FOstats_energy_mri' u'FOstats_entropy_mri' u'FOstats_kurtosis_mri'\n",
      " u'FOstats_mean_mri' u'FOstats_variance_mri' u'ShapeSize_max_euc_dis_mri'\n",
      " u'ShapeSize_spherical_disproportion_mri' u'ShapeSize_sphericity_mri'\n",
      " u'ShapeSize_surf_area_cm2_mri' u'ShapeSize_surface2volratio_mri'\n",
      " u'ShapeSize_vol_cm3_mri' u'texture_autocorrelation_avg_mri'\n",
      " u'texture_cluster_prominence_avg_mri' u'texture_cluster_shade_avg_mri'\n",
      " u'texture_cluster_tendency_avg_mri' u'texture_contrast_avg_mri'\n",
      " u'texture_diff_entropy_avg_mri' u'texture_dissimilarity_avg_mri'\n",
      " u'texture_energy_avg_mri' u'texture_entropy_avg_mri'\n",
      " u'texture_homogeneity1_avg_mri' u'texture_homogeneity2_avg_mri'\n",
      " u'texture_idn_avg_mri' u'texture_maxprob_avg_mri'\n",
      " u'texture_sum_avg_avg_mri' u'texture_sum_entropy_avg_mri'\n",
      " u'texture_sum_var_avg_mri' u'texture_imc2_avg_mri'\n",
      " u'texture_diff_avg_avg_mri' u'texture_diff_var_avg_mri'\n",
      " u'texture_avg_intensity_avg_mri' u'texture_sum_squares_avg_mri'\n",
      " u'FOstats_min_mri' u'FOstats_max_mri' u'FOstats_energy_pet'\n",
      " u'FOstats_entropy_pet' u'FOstats_kurtosis_pet' u'FOstats_mean_pet'\n",
      " u'FOstats_min_pet' u'FOstats_max_pet' u'FOstats_uniformity_pet'\n",
      " u'FOstats_variance_pet' u'ShapeSize_compactness1_pet'\n",
      " u'ShapeSize_compactness2_pet' u'ShapeSize_max_euc_dis_pet'\n",
      " u'ShapeSize_spherical_disproportion_pet' u'ShapeSize_sphericity_pet'\n",
      " u'ShapeSize_surface2volratio_pet' u'ShapeSize_vol_cm3_pet'\n",
      " u'texture_autocorrelation_avg_pet' u'texture_cluster_prominence_avg_pet'\n",
      " u'texture_cluster_shade_avg_pet' u'texture_cluster_tendency_avg_pet'\n",
      " u'texture_contrast_avg_pet' u'texture_correlation_avg_pet'\n",
      " u'texture_diff_entropy_avg_pet' u'texture_dissimilarity_avg_pet'\n",
      " u'texture_energy_avg_pet' u'texture_entropy_avg_pet'\n",
      " u'texture_homogeneity1_avg_pet' u'texture_homogeneity2_avg_pet'\n",
      " u'texture_idmn_avg_pet' u'texture_idn_avg_pet' u'texture_inv_var_avg_pet'\n",
      " u'texture_maxprob_avg_pet' u'texture_sum_avg_avg_pet'\n",
      " u'texture_sum_entropy_avg_pet' u'texture_sum_var_avg_pet'\n",
      " u'texture_imc1_avg_pet' u'texture_imc2_avg_pet'\n",
      " u'texture_diff_avg_avg_pet' u'texture_diff_var_avg_pet'\n",
      " u'texture_avg_intensity_avg_pet' u'texture_sum_squares_avg_pet']\n",
      "outcome: Tumor_Grade_Binary\n",
      "\n",
      "texture_inv_var_avg_pet (90.6%)\n",
      "texture_homogeneity1_avg_pet (85.6%)\n",
      "texture_homogeneity2_avg_pet (83.7%)\n",
      "FOstats_entropy_pet (79.5%)\n",
      "texture_sum_avg_avg_pet (78.4%)\n",
      "texture_avg_intensity_avg_pet (78.4%)\n",
      "FOstats_mean_pet (78.2%)\n",
      "texture_entropy_avg_pet (76.5%)\n",
      "texture_sum_entropy_avg_pet (72.4%)\n",
      "texture_diff_avg_avg_pet (70.3%)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# find 'important' features for Logistic Regression\\\n",
    "coeff_thresh = 0.01\n",
    "for oc in outcome_names:\n",
    "    json_fname = '{}/Learner/{}_IDV{}_DV{}_Trial{}_{}folds.json'.format(im_dir, the_clf_name, ID_var_name, oc, n_trial, k_fold)\n",
    "    df_learning_output = pd.read_json(json_fname)\n",
    "#     print(len(df_learning_output.index.tolist()))\n",
    "    for ii in df_learning_output.index:\n",
    "        feat_imp = np.array(df_learning_output['feat_importance'][ii])\n",
    "        feat_names = np.array(df_learning_output['feat_name'][ii])\n",
    "\n",
    "        # find a list of features that are not dropped by ElasticNet\n",
    "        lst_tmp = feat_names[np.abs(feat_imp) > coeff_thresh]\n",
    "        if ii == 0:\n",
    "            #initialize the dictionary\n",
    "            dct_feat_tally = {}\n",
    "            for ss in lst_tmp:\n",
    "                dct_feat_tally[ss] = 1\n",
    "        else:\n",
    "            for ss in lst_tmp:\n",
    "                if ss in dct_feat_tally.keys():\n",
    "                    dct_feat_tally[ss] += 1\n",
    "                else:\n",
    "                    dct_feat_tally[ss] = 1\n",
    "    \n",
    "    # sort the feat tally dictionary\n",
    "    sorted_dct_feat_tally = sorted(dct_feat_tally.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    top10_feat = sorted_dct_feat_tally[0:10]\n",
    "    \n",
    "    max_count = len(df_learning_output)\n",
    "    print('outcome: {}\\n'.format(oc))\n",
    "    for (feat, count) in top10_feat:\n",
    "        print('{} ({:.1%})'.format(feat, float(count/max_count)))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, auc, roc_curve\n",
    "from scipy.stats import zscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in all radiomic data\n",
    "fname = '{}/data_all.csv'.format(im_dir)\n",
    "df_data = pd.read_csv(fname)\n",
    "pat = re.compile('texture_|FOstats_|ShapeSize_')\n",
    "feat_names = [ss for ss in df_data.columns.tolist() if pat.match(ss)]\n",
    "feat_tag = 'pet_mr_radiomics'\n",
    "\n",
    "# scale the features to z-score\n",
    "df_data[feat_names] = df_data[feat_names].apply(zscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_data.MRN.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the learning output data and more\n",
    "fname = '{}/Learner/CLF_output_all.csv'.format(im_dir)\n",
    "df_clf_all = pd.read_csv(fname)\n",
    "\n",
    "# simplify clf name\n",
    "def simplify_clf_name_func(x):\n",
    "    if re.search('(.+)LogReg',x):\n",
    "        return 'LogReg'\n",
    "    else:\n",
    "        return x\n",
    "df_clf_all['clf_name_simplify'] = df_clf_all['clf_name'].map(simplify_clf_name_func)\n",
    "# print(df_clf_all.ix[:,['clf_name_simplify', 'clf_name']])\n",
    "\n",
    "# # drop the one with Random Forest since we would like to use logistic regression only\n",
    "# df_clf_all.drop(df_clf_all[(df_clf_all.Dep_var == 'DF_1yr') & (df_clf_all.clf_name == 'RandomForest')].index, inplace=True)\n",
    "# idx = df_clf_all.groupby('Dep_var').apply(lambda df: df.AUC_mean.argmax())  \n",
    "\n",
    "dct_clf = {'ElasticNet': SGDClassifier(), 'LogReg': LogisticRegression(), 'RandomForest': RandomForestClassifier(),\n",
    "          'SVM': SVC()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [idx[3]]\n",
    "print(test)\n",
    "for ii in test:\n",
    "#     clf_name, clf_name_simple, oc, n_trial, k_fold = df_clf_all.ix[ii, ['clf_name', 'clf_name_simplify', 'Dep_var', 'n_trial', 'k_fold']].tolist()\n",
    "    json_fname = '{}/Learner/{}_IDV{}_DV{}_Trial{}_{}folds.json'.format(im_dir, the_clf_name, feat_name, oc, n_trial, k_fold)\n",
    "    df_learning_output = pd.read_json(json_fname)\n",
    "    lst_data_all = []\n",
    "    for iid in df_learning_output.index:\n",
    "        dct_param = df_learning_output['best_params'][iid]\n",
    "        if iid == 0: # determine what to average on the first round\n",
    "            lst_num_var = []\n",
    "            for k, val in dct_param.items():\n",
    "               if isinstance(val, numbers.Number):\n",
    "                lst_num_var.append(k)\n",
    "            lst_str_var = set(lst_num_var).symmetric_difference(dct_param.keys())\n",
    "        lst_tmp = [dct_param[s] for s in lst_num_var]\n",
    "        tmp = dict(zip(lst_num_var, lst_tmp))\n",
    "        lst_data_all.append(tmp)\n",
    "        \n",
    "    df_data_all = pd.DataFrame(lst_data_all)\n",
    "    df_data_all = df_data_all.ix[:, lst_num_var]\n",
    "    \n",
    "    # create the final parameter with the average over all numerical variables\n",
    "    final_param = dict(df_data_all.mean())\n",
    "    \n",
    "    # add the string parameter variabls\n",
    "    for ss in lst_str_var:\n",
    "        final_param[ss] = dct_param[ss]\n",
    "    print(final_param)\n",
    "        \n",
    "    # get all the needed radiomic data\n",
    "    df_tmp = df_data.ix[:,feat_names + [oc]]\n",
    "    df_tmp = df_tmp.dropna()\n",
    "    X, y = df_tmp.ix[:,feat_names].as_matrix(), df_tmp.ix[:,oc].astype('int').as_matrix()\n",
    "    clf = dct_clf[the_clf_name]\n",
    "    print(clf)\n",
    "    clf.set_params(**final_param)\n",
    "    clf.fit(X, y)\n",
    "    feat_importance = getattr(clf, 'feature_importances_', None)\n",
    "    if feat_importance is None and hasattr(clf, 'coef_'):\n",
    "        feat_importance = clf.coef_\n",
    "    print(feat_importance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp = np.array(df_learning_output['feat_importance'][4])\n",
    "feat_name = np.array(df_learning_output['feat_name'][4])\n",
    "print(feat_name[feat_imp != 0.0])\n",
    "print(feat_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for easier interpretbaility of output, we will use elasticNet for reporting feature importance for all outcome!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
