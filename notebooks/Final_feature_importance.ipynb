{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numbers\n",
    "import operator\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ID_var_name = 'pet_mr_radiomics'\n",
    "\n",
    "df_yr = range(1,6,1)\n",
    "outcome_names = ['DF_{}yr'.format(yy) for yy in df_yr]\n",
    "\n",
    "n_trial = 1000\n",
    "k_fold = 3\n",
    "\n",
    "rootdir = '/Users/shuang/Documents/Proj_Radiomics/Data/her2'\n",
    "the_mri_tp = 2\n",
    "the_mri_bin_width = 5\n",
    "the_pet_bin_width = 0.1\n",
    "im_dir = '{}/her2_Analysis/PETMRI/PETbinwidth{:.1f}_MRItp{}_binwidth{}'.format(rootdir,the_pet_bin_width, the_mri_tp, the_mri_bin_width)\n",
    "\n",
    "# the selected model to use for all DF outcome\n",
    "the_clf_name = 'ElasticNet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outcome: DF_1yr\n",
      "\n",
      "texture_idn_avg_mri (0.991)\n",
      "texture_idmn_avg_mri (0.841)\n",
      "texture_cluster_prominence_avg_pet (0.83)\n",
      "FOstats_entropy_mri (0.815)\n",
      "FOstats_mean_mri (0.775)\n",
      "texture_sum_entropy_avg_mri (0.7623333333333333)\n",
      "texture_sum_avg_avg_mri (0.7466666666666667)\n",
      "texture_avg_intensity_avg_mri (0.7466666666666667)\n",
      "FOstats_min_mri (0.7386666666666667)\n",
      "texture_diff_entropy_avg_mri (0.72)\n",
      "\n",
      "\n",
      "outcome: DF_2yr\n",
      "\n",
      "FOstats_mean_mri (0.9816666666666667)\n",
      "texture_sum_avg_avg_mri (0.9806666666666667)\n",
      "texture_avg_intensity_avg_mri (0.9806666666666667)\n",
      "FOstats_min_mri (0.9663333333333334)\n",
      "FOstats_max_mri (0.894)\n",
      "texture_idn_avg_mri (0.8746666666666667)\n",
      "texture_diff_avg_avg_mri (0.8713333333333333)\n",
      "texture_dissimilarity_avg_mri (0.8713333333333333)\n",
      "FOstats_min_pet (0.8626666666666667)\n",
      "ShapeSize_compactness2_mri (0.843)\n",
      "\n",
      "\n",
      "outcome: DF_3yr\n",
      "\n",
      "FOstats_mean_mri (0.9893333333333333)\n",
      "texture_sum_avg_avg_mri (0.9836666666666667)\n",
      "texture_avg_intensity_avg_mri (0.9836666666666667)\n",
      "FOstats_min_mri (0.968)\n",
      "texture_diff_avg_avg_mri (0.85)\n",
      "texture_dissimilarity_avg_mri (0.85)\n",
      "FOstats_max_mri (0.8476666666666667)\n",
      "ShapeSize_compactness2_mri (0.8363333333333334)\n",
      "ShapeSize_compactness2_pet (0.8323333333333334)\n",
      "FOstats_min_pet (0.817)\n",
      "\n",
      "\n",
      "outcome: DF_4yr\n",
      "\n",
      "FOstats_min_mri (0.9426666666666667)\n",
      "FOstats_mean_mri (0.9323333333333333)\n",
      "texture_sum_avg_avg_mri (0.9133333333333333)\n",
      "texture_avg_intensity_avg_mri (0.9133333333333333)\n",
      "texture_cluster_prominence_avg_pet (0.8556666666666667)\n",
      "texture_imc2_avg_mri (0.8546666666666667)\n",
      "ShapeSize_compactness2_pet (0.826)\n",
      "FOstats_max_mri (0.7953333333333333)\n",
      "ShapeSize_compactness2_mri (0.792)\n",
      "texture_idn_avg_mri (0.7793333333333333)\n",
      "\n",
      "\n",
      "outcome: DF_5yr\n",
      "\n",
      "FOstats_min_mri (0.9203333333333333)\n",
      "texture_cluster_prominence_avg_pet (0.798)\n",
      "texture_idn_avg_pet (0.787)\n",
      "texture_imc2_avg_mri (0.7843333333333333)\n",
      "ShapeSize_max_euc_dis_pet (0.771)\n",
      "FOstats_mean_mri (0.7456666666666667)\n",
      "texture_sum_avg_avg_mri (0.7016666666666667)\n",
      "texture_avg_intensity_avg_mri (0.7016666666666667)\n",
      "texture_idn_avg_mri (0.6976666666666667)\n",
      "FOstats_energy_mri (0.69)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# find 'important' features\n",
    "for oc in outcome_names:\n",
    "    json_fname = '{}/Learner/{}_IDV{}_DV{}_Trial{}_{}folds.json'.format(im_dir, the_clf_name, ID_var_name, oc, n_trial, k_fold)\n",
    "    df_learning_output = pd.read_json(json_fname)\n",
    "    for ii in df_learning_output.index:\n",
    "        feat_imp = np.array(df_learning_output['feat_importance'][ii])\n",
    "        feat_names = np.array(df_learning_output['feat_name'][ii])\n",
    "        \n",
    "        # find a list of features that are not dropped by ElasticNet\n",
    "        lst_tmp = feat_names[feat_imp != 0.0]\n",
    "        if ii == 0:\n",
    "            #initialize the dictionary\n",
    "            dct_feat_tally = {}\n",
    "            for ss in lst_tmp:\n",
    "                dct_feat_tally[ss] = 1\n",
    "        else:\n",
    "            for ss in lst_tmp:\n",
    "                if ss in dct_feat_tally.keys():\n",
    "                    dct_feat_tally[ss] += 1\n",
    "                else:\n",
    "                    dct_feat_tally[ss] = 1\n",
    "    \n",
    "    # sort the feat tally dictionary\n",
    "    sorted_dct_feat_tally = sorted(dct_feat_tally.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    top10_feat = sorted_dct_feat_tally[0:10]\n",
    "    \n",
    "    max_count = len(df_learning_output)\n",
    "    print('outcome: {}\\n'.format(oc))\n",
    "    for (feat, count) in top10_feat:\n",
    "        print('{} ({})'.format(feat, float(count/max_count)))\n",
    "    print('\\n')\n",
    "#     print(sorted_dct_feat_tally)\n",
    "#     for k, value in sorted_dct_feat_tally.items():\n",
    "#         print('feat name: {}, count: {}'.format(k, value))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, auc, roc_curve\n",
    "from scipy.stats import zscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read in all radiomic data\n",
    "fname = '{}/data_all.csv'.format(im_dir)\n",
    "df_data = pd.read_csv(fname)\n",
    "pat = re.compile('texture_|FOstats_|ShapeSize_')\n",
    "feat_names = [ss for ss in df_data.columns.tolist() if pat.match(ss)]\n",
    "feat_tag = 'pet_mr_radiomics'\n",
    "\n",
    "# scale the features to z-score\n",
    "df_data[feat_names] = df_data[feat_names].apply(zscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_data.MRN.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read the learning output data and more\n",
    "fname = '{}/Learner/CLF_output_all.csv'.format(im_dir)\n",
    "df_clf_all = pd.read_csv(fname)\n",
    "\n",
    "# simplify clf name\n",
    "def simplify_clf_name_func(x):\n",
    "    if re.search('(.+)LogReg',x):\n",
    "        return 'LogReg'\n",
    "    else:\n",
    "        return x\n",
    "df_clf_all['clf_name_simplify'] = df_clf_all['clf_name'].map(simplify_clf_name_func)\n",
    "# print(df_clf_all.ix[:,['clf_name_simplify', 'clf_name']])\n",
    "\n",
    "# # drop the one with Random Forest since we would like to use logistic regression only\n",
    "# df_clf_all.drop(df_clf_all[(df_clf_all.Dep_var == 'DF_1yr') & (df_clf_all.clf_name == 'RandomForest')].index, inplace=True)\n",
    "# idx = df_clf_all.groupby('Dep_var').apply(lambda df: df.AUC_mean.argmax())  \n",
    "\n",
    "dct_clf = {'ElasticNet': SGDClassifier(), 'LogReg': LogisticRegression(), 'RandomForest': RandomForestClassifier(),\n",
    "          'SVM': SVC()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31]\n",
      "/Users/shuang/Documents/Proj_Radiomics/Data/her2/her2_Analysis/PETMRI/PETbinwidth0.1_MRItp2_binwidth5/Learner/ElasticNet_IDVpet_mr_radiomics_DVDF_3yr_Trial10_3folds.json\n",
      "{'alpha': 0.68797000000000097, 'l1_ratio': 0.48666666666666664, 'max_iter': 49933.333333333336, 'loss': 'log', 'penalty': 'elasticnet'}\n",
      "SGDClassifier(alpha=0.68797000000000097, average=False, class_weight=None,\n",
      "       epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.48666666666666664, learning_rate='optimal', loss='log',\n",
      "       max_iter=49933.333333333336, n_iter=None, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       tol=None, verbose=0, warm_start=False)\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "test = [idx[3]]\n",
    "print(test)\n",
    "for ii in test:\n",
    "#     clf_name, clf_name_simple, oc, n_trial, k_fold = df_clf_all.ix[ii, ['clf_name', 'clf_name_simplify', 'Dep_var', 'n_trial', 'k_fold']].tolist()\n",
    "    json_fname = '{}/Learner/{}_IDV{}_DV{}_Trial{}_{}folds.json'.format(im_dir, the_clf_name, feat_name, oc, n_trial, k_fold)\n",
    "    df_learning_output = pd.read_json(json_fname)\n",
    "    lst_data_all = []\n",
    "    for iid in df_learning_output.index:\n",
    "        dct_param = df_learning_output['best_params'][iid]\n",
    "        if iid == 0: # determine what to average on the first round\n",
    "            lst_num_var = []\n",
    "            for k, val in dct_param.items():\n",
    "               if isinstance(val, numbers.Number):\n",
    "                lst_num_var.append(k)\n",
    "            lst_str_var = set(lst_num_var).symmetric_difference(dct_param.keys())\n",
    "        lst_tmp = [dct_param[s] for s in lst_num_var]\n",
    "        tmp = dict(zip(lst_num_var, lst_tmp))\n",
    "        lst_data_all.append(tmp)\n",
    "        \n",
    "    df_data_all = pd.DataFrame(lst_data_all)\n",
    "    df_data_all = df_data_all.ix[:, lst_num_var]\n",
    "    \n",
    "    # create the final parameter with the average over all numerical variables\n",
    "    final_param = dict(df_data_all.mean())\n",
    "    \n",
    "    # add the string parameter variabls\n",
    "    for ss in lst_str_var:\n",
    "        final_param[ss] = dct_param[ss]\n",
    "    print(final_param)\n",
    "        \n",
    "    # get all the needed radiomic data\n",
    "    df_tmp = df_data.ix[:,feat_names + [oc]]\n",
    "    df_tmp = df_tmp.dropna()\n",
    "    X, y = df_tmp.ix[:,feat_names].as_matrix(), df_tmp.ix[:,oc].astype('int').as_matrix()\n",
    "    clf = dct_clf[the_clf_name]\n",
    "    print(clf)\n",
    "    clf.set_params(**final_param)\n",
    "    clf.fit(X, y)\n",
    "    feat_importance = getattr(clf, 'feature_importances_', None)\n",
    "    if feat_importance is None and hasattr(clf, 'coef_'):\n",
    "        feat_importance = clf.coef_\n",
    "    print(feat_importance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['texture_idn_avg_mri' 'texture_cluster_shade_avg_pet']\n",
      "[ 0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.26841557  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.18527969\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.        ]\n"
     ]
    }
   ],
   "source": [
    "feat_imp = np.array(df_learning_output['feat_importance'][4])\n",
    "feat_name = np.array(df_learning_output['feat_name'][4])\n",
    "print(feat_name[feat_imp != 0.0])\n",
    "print(feat_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `OrderedDict` not found.\n"
     ]
    }
   ],
   "source": [
    "# for easier interpretbaility of output, we will use elasticNet for reporting feature importance for all outcome!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('texture_imc2_avg_mri', 25),\n",
       " ('FOstats_mean_mri', 25),\n",
       " ('texture_idn_avg_pet', 25),\n",
       " ('texture_idn_avg_mri', 24),\n",
       " ('ShapeSize_max_euc_dis_pet', 24),\n",
       " ('texture_avg_intensity_avg_mri', 24),\n",
       " ('texture_sum_avg_avg_mri', 24),\n",
       " ('texture_cluster_prominence_avg_pet', 21),\n",
       " ('texture_diff_avg_avg_mri', 20)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
